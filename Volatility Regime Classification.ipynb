{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbb5f0d-5987-473b-896a-23caaf33202b",
   "metadata": {},
   "source": [
    "# Regime Classification with Dynamic Voaltility Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d61d9a4-62e2-43f6-8910-e30623c0634e",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4fb2f1-18be-4ce9-9cdc-936bda09e9ad",
   "metadata": {},
   "source": [
    "**Motivation:**   \n",
    "Volatility regime classification is a hot topic. so we will try out two models to classify them. \n",
    "    \n",
    "**Objectives:**  \n",
    "1. Dynamic volatility modelling with Generalized AutoRegressive Conditional Heteroskedasticity - GARCH(1,1)  \n",
    "2. Volatility model parameter optimisation  \n",
    "3. Volatility regime classification with Markov Models\n",
    "4. Classification model performance evaluation  \n",
    "        \n",
    "**Flow of Analysis & Explanations:**  \n",
    "1. Analysis of the return distribution: \n",
    "> We will look at the higher moments of the return distribution.  \n",
    "> Then we will use statistical tests to determine if the distribution has 'zero mean' as well as if the distribution follows a normal distribution.  \n",
    "> These tests are important in determining the volatility model assumpotions, such as the mean model and distribution assumptions.  \n",
    "2. GARCH(1,1) Modelling  \n",
    "> we will construct the volatility model based on the results we obetained above and optimise the parameters (Optimisation is embeded in the function).    \n",
    "> we will then compare the market volatility model against the VIX index to understand that the implied volatility will be different from conditional as the market may not assume risk neutrality.  \n",
    "3. Hidden Markov Model \n",
    "> Hidden markov model is one of the often mentioned perhaps due to the success of renaissance technology.  \n",
    "> We will examine the performance of the model, how to improve on the model and if the assumptions are actually correct.  \n",
    "4. Markov Switching Autoregressive Model\n",
    "> This model was covered by a few papers.   \n",
    "> While the model performs better than HMM, the model has its own issues such as computation time and MLE convergence issue.  \n",
    "    \n",
    "**NOTE**  \n",
    "The legend in HMM can be wrongly labelled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e907674-3d16-4fb1-9049-23b2be86ba92",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454c300-7fa8-4f1f-93a1-29f727e565ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime as dt \n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import arch\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be86cb6c-bb88-4a32-ba6a-ad9886bb1107",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b55ad7-70f2-4143-9646-5f5a77fce405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data & processing\n",
    "\n",
    "def get_return(ticker, period, interval):\n",
    "    \n",
    "    #############################\n",
    "    # input: ticker and interval\n",
    "    # output: return\n",
    "    \n",
    "    ticker = yf.Ticker(str(ticker))\n",
    "    data = ticker.history(period = str(period), interval = str(interval))\n",
    "    rt = data.Close.pct_change().dropna()\n",
    "    \n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867a529-0b7c-4a40-9e70-30a1907c18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = get_return(ticker = '^GSPC', period = 'max', interval = '1d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2b114-eeba-4374-8960-bb9b2cc3471b",
   "metadata": {},
   "source": [
    "### Stylised facts of return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7f8ea8-7d3e-4ece-9b55-1f406257ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dist_stats(asset_return):\n",
    "    \n",
    "    ################################\n",
    "    # Input: return series\n",
    "    # output: stats and chart\n",
    "\n",
    "    plt = px.histogram(asset_return, marginal= \"violin\")\n",
    "    \n",
    "    print('Statistics of the retrun distribution')\n",
    "    print('-' * 50)\n",
    "    print('Length of the return series:', asset_return.shape)\n",
    "    print('Mean:', asset_return.mean()*100, '%')\n",
    "    print('Standard Deviation:', asset_return.std()*100, '%')\n",
    "    print('Skew:', asset_return.skew())\n",
    "    print('Kurtosis:', asset_return.kurtosis())\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1850a6-375d-4763-9174-e77cf0579a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_dist_stats(rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1319d953-9f11-4fcc-b0bf-dd86b61ae387",
   "metadata": {},
   "source": [
    "Based on the above statistics, we know the distribution is leaning to the positive side (negative skew) and narrow (positive kurtosis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693e01b6-c0df-41a7-b8eb-35707983071a",
   "metadata": {},
   "source": [
    "### Hypothesis testing for mean return and distribution normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c133f0-5ab0-45d2-9907-9926628f3b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dist(asset_return, mode, alpha = 1e-2):\n",
    "    ##############################\n",
    "    # Input: return and test('mean' or 'normal'), alpha in decimals\n",
    "    # output: P value and test result\n",
    "    \n",
    "    if (mode == 'mean'):\n",
    "        t_stat, p = stats.ttest_1samp(asset_return, popmean=0, alternative='two-sided')\n",
    "    elif (mode == 'normal'):\n",
    "        k2, p = stats.normaltest(rt)\n",
    "    \n",
    "    def test(p, alpha):\n",
    "        print(\"p = {:g}\".format(p))\n",
    "        if p < alpha: \n",
    "            print(\"The null hypothesis can be rejected\")\n",
    "        else:\n",
    "            print(\"The null hypothesis cannot be rejected\")\n",
    "            \n",
    "    return test(p, alpha)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa8174-2e7a-434c-92d2-01cbd1adb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dist(rt, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290e901-812c-4144-81c6-cf77fd74353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dist(rt, 'normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1281637-230f-4b77-986d-d86dca59703d",
   "metadata": {},
   "source": [
    "From the above testing, we can be confident that the return distribution has a non-zero mean and the return is not normally distributed.  \n",
    "Since the mean is non-zero, we will model the volatility with a conditional mean model, in this case hetergenous autoregressive model.  \n",
    "Using this mean model, the mean includes a component of an average of the mean during the lag period.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10a891c-fae3-4961-91ad-e1b10d0ce99b",
   "metadata": {},
   "source": [
    "## Volatility Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0934444-52a2-4a30-bf9f-b96716104bba",
   "metadata": {},
   "source": [
    "### GARCH(1,1)\n",
    "The package ARCH will perform parameter optimisation of the model automatically.  \n",
    "since the return distribution is not normal, we can choose alternative distributions to model the volatility.  \n",
    "we are using heterogenous autoregressive mean and skewed student's t disrtibution based on maximum likelihood.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b237c-dac5-4b08-a7c8-1c7f932093f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = arch.univariate.arch_model(rt, x=None, \n",
    "                                mean='HARX', lags=0, \n",
    "                                vol='Garch', p=1, o=0, q=1, \n",
    "                                dist='skewt', hold_back=None, rescale=True)\n",
    "\n",
    "volatility_model = am.fit()\n",
    "volatility_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb9e853-851e-49d2-a1d4-21b31cad3518",
   "metadata": {},
   "source": [
    "### Long-term variance under GARCH(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b2658b-ed1b-4c13-8a7a-5b6531c2fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642a64d-10ad-4ff3-9dd6-054aba99f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Model Parameters\n",
    "const, omega, alpha, beta, eta, lamb = volatility_model.params\n",
    "\n",
    "# Retrieve conditional volatility\n",
    "garch_vol = volatility_model.conditional_volatility.round(2) * np.sqrt(252)\n",
    "\n",
    "# long-term variance under GARCH\n",
    "VL = omega / (1 - alpha - beta )\n",
    "\n",
    "# long-term volatility under GARCH (convert from variance)\n",
    "sigma_L = np.sqrt(VL) * np.sqrt(252) # already measured in percentage\n",
    "\n",
    "# sample volatility estimate\n",
    "sample_sigma = rt.std() *np.sqrt(252) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f0c93-383e-44e4-98a7-4145e2cfae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatlity Plot Function\n",
    "def vol_plot(garch, vl, std):\n",
    "    \n",
    "    fig = px.line(garch,title=\"GARCH(1,1)\")\n",
    "\n",
    "    fig.add_hline(y=vl, line_dash=\"dash\", line_color=\"green\", annotation_text=\"Long-run variance estimate\")\n",
    "\n",
    "    fig.add_hline(y=std, line_dash=\"dash\", line_color=\"red\", annotation_text=\"Sample variance\")\n",
    "\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67944df4-3ecd-471d-b77f-33ae02904f76",
   "metadata": {},
   "source": [
    "### Plot Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc4d9f-f23d-4bf0-9fae-da0fb52d4b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_plot(garch_vol, sigma_L, sample_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765e10ab-6aa5-4fbe-a108-bc03e22eb914",
   "metadata": {},
   "source": [
    "### Comparison with VIX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bdf33d-bba7-4c96-ba3f-d1ee981dab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data & processing\n",
    "ticker = yf.Ticker(\"^VIX\")\n",
    "vix = ticker.history(period = 'max', interval = \"1d\")\n",
    "vix = vix.Close\n",
    "\n",
    "val_data = pd.DataFrame([vix, garch_vol]).T.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92455126-127d-4805-a5e4-580cf958c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(val_data, line_shape='hv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255a3687-c029-4686-a018-63f432d44f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(val_data.Close - val_data.cond_vol , marginal= \"violin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb383529-73b8-40aa-b3a3-09db75ffdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Absolute Error: ', mean_absolute_error(val_data.iloc[:,0], val_data.iloc[:,1]))\n",
    "\n",
    "test_dist(val_data.Close - val_data.cond_vol, 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42262c87-6588-4b0d-b53d-a2affdca820c",
   "metadata": {},
   "source": [
    "So we know that the mean difference between model and market is significant.  \n",
    "However, VIX measures the implied volatility based on option price but our model measures the conditional volatility of the market.   \n",
    "These two are distinctly different and they are supposed to.     \n",
    "Implied higher than conditional volatility suggests the pricing of options may not be risk neutral.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bcdee8-6461-486f-b000-fa65824bf903",
   "metadata": {},
   "source": [
    "## Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b912788-7ed3-442c-94be-54ce19d2ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitHMM(vol, n_states):\n",
    "    \n",
    "    train_vals = np.expand_dims(vol, 1)\n",
    "    \n",
    "    train_vals = np.reshape(train_vals,[len(vol),1])\n",
    "    \n",
    "    # fit Gaussian HMM to Q\n",
    "    model = GaussianHMM(n_components=n_states, n_iter=100).fit(train_vals)\n",
    "     \n",
    "    # classify each observation as state 0 or 1\n",
    "    hidden_states = model.predict(train_vals)\n",
    "    post_prob = np.array(model.predict_proba(train_vals))\n",
    " \n",
    "    # fit HMM parameters\n",
    "    mus = np.squeeze(model.means_)\n",
    "    sigmas = np.squeeze(np.sqrt(model.covars_))\n",
    "    transmat = np.array(model.transmat_)\n",
    "    print(mus)\n",
    "    print(sigmas)\n",
    "    \n",
    "    relabeled_states = hidden_states\n",
    "    return (relabeled_states, mus, sigmas, transmat, post_prob, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c06dc-11cf-4538-9630-1311b3983163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(dates, vol, post_prob, export_label):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=dates, y=vol, name=\"GARCH\", mode='lines', line_shape='hv', yaxis = 'y1'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=dates, y=post_prob.iloc[:,0], name = 'Pr(Low Vol Regime)', mode='lines', line_shape='hv',\n",
    "                             line=dict(width=0.5, color='green'), \n",
    "                             stackgroup='two', yaxis = 'y2'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=dates, y=post_prob.iloc[:,1], name = 'Pr(Medium Vol Regime)', mode='lines', line_shape='hv',\n",
    "                             line=dict(width=0.5, color='orange'),\n",
    "                             stackgroup='two', yaxis = 'y2'))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=dates, y=post_prob.iloc[:,2], name = 'Pr(High Vol Regime)', mode='lines', line_shape='hv',\n",
    "                             line=dict(width=0.5, color='red'),\n",
    "                             stackgroup='two', yaxis = 'y2'))\n",
    "\n",
    "    # Create axis objects\n",
    "    fig.update_layout(\n",
    "        title = (\"Volatility Regime - \" + str(export_label)),\n",
    "\n",
    "        yaxis=dict(title=\"Volatility\"),\n",
    "\n",
    "        yaxis2=dict(title=\"Posterier Probability\", overlaying=\"y1\", side=\"right\")\n",
    "\n",
    "    )\n",
    "\n",
    "    fig.write_html('Volatility Regime Classification - ' + str(export_label) + '.html') \n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46fafd-3c26-4263-ba1e-83bff71c43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states, mus, sigmas, transmat, post_prob, hmm_model = fitHMM(garch_vol, 3)\n",
    "dates = garch_vol.index\n",
    "\n",
    "hmm_data = pd.DataFrame([dates, garch_vol, hidden_states], \n",
    "                        index = [\"date\", \"volatility\", \"hidden_states\"]).T\n",
    "\n",
    "hmm_prob = pd.DataFrame(post_prob, columns = ['state_1', 'state_2', 'state_3'])\n",
    "hmm_data = pd.concat([hmm_data, hmm_prob], axis=1)\n",
    "\n",
    "hmm_data.date = pd.to_datetime(hmm_data.date)\n",
    "hmm_data = hmm_data.sort_values(by=\"date\")\n",
    "\n",
    "hmm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991afe48-29ca-407b-93ac-4870039c8525",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(hmm_data.date, hmm_data.volatility, hmm_prob, 'HMM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d3001-fe2f-405c-994f-3cd4caf5daa4",
   "metadata": {},
   "source": [
    "## Markov Switching Autoregression Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c41c0f-d574-4a5f-bf46-8045764b23ba",
   "metadata": {},
   "source": [
    "Intuitively, volatility regime change can be fast, yet the transition does not necessarily have to be instantaneous. The HMM model does not appear to be perform well under this intuition.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1bc24c-a080-40ee-bf0b-a4fc89467d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "mod_hamilton = sm.tsa.MarkovAutoregression(rt-rt.mean(), k_regimes=3, order = 1, trend=\"n\", switching_ar = False, switching_variance = True)\n",
    "    \n",
    "res_hamilton = mod_hamilton.fit()\n",
    "res_hamilton.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab880d8c-b6f6-4e7e-85c4-fb3a4ac28ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_prob = res_hamilton.smoothed_marginal_probabilities\n",
    "post_prob = pd.DataFrame(post_prob)\n",
    "\n",
    "plot_model(dates, garch_vol, post_prob, 'MSAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327ea97b-5b48-480f-9288-a5a6cb7e3344",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e78e2-d1be-462d-8ef8-65de4a471961",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_log_prob = hmm_model.score(np.expand_dims(garch_vol,1))\n",
    "print('log-likelihood of HMM:', hmm_log_prob)\n",
    "print('Transition Matrix of MSAR:')\n",
    "print(transmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97247184-5ee8-417c-9c5c-f2e5b5c87b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "msar_log_prob = mod_hamilton.loglike(res_hamilton.params)\n",
    "trans_matrix = mod_hamilton.regime_transition_matrix(res_hamilton.params)\n",
    "print('Log-likelihood of MSAR:', msar_log_prob)\n",
    "print('Transition Matrix of MSAR:')\n",
    "print(trans_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce0626",
   "metadata": {},
   "source": [
    "Hidden Markov Model has a lower log likelihood value than the Markov Switching Autoregressive Model,    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc89c61-d9c0-47f4-a7d0-4319bc9e30f6",
   "metadata": {},
   "source": [
    "## References  \n",
    "**By section:**  \n",
    "1. Return distributional Assumptions  \n",
    "> ARCH Model https://www.fsb.miamioh.edu/lij14/672_2014_s5.pdf  \n",
    "> Heterogeneous Auroregressive Mean Model https://arch.readthedocs.io/en/latest/univariate/generated/arch.univariate.HARX.html#arch.univariate.HARX  \n",
    "> Garch Forecasting Performance under Different Distribution Assumptions http://www-stat.wharton.upenn.edu/~steele/Courses/434/434Context/GARCH/Willhelmesson06.pdf  \n",
    "\n",
    "2. Volatility Modelling\n",
    "> Predicting volatility with heterogeneous autoregressive models https://www.sr-sv.com/predicting-volatility-with-heterogeneous-autoregressive-models/   \n",
    "\n",
    "\n",
    "3. Hidden Markov Model\n",
    "> Practical Time Series Analysis - code repo https://github.com/PracticalTimeSeriesAnalysis/BookRepo      \n",
    "> HMMLearn https://hmmlearn.readthedocs.io/en/latest/\n",
    "> Quantstrat HMM https://www.quantstart.com/articles/market-regime-detection-using-hidden-markov-models-in-qstrader/\n",
    "\n",
    "4. Markov Switching Autoregressive Model\n",
    "> ECB Volatility Regime https://www.ecb.europa.eu/pub/financial-stability/fsr/focus/2018/pdf/ecb~bcaaae16c3.fsrbox201805_03.pdf  \n",
    "> Autoregressive conditional heteroskedasticity and changes in regime https://www.sciencedirect.com/science/article/abs/pii/0304407694900671    \n",
    "> Markov-Switching - Kim, Nelson, and Startz (1998) Three-state Variance Switching http://www.chadfulton.com/topics/mar_kim_nelson_startz.html   \n",
    "> Statsmodels Variance Switching Model https://www.statsmodels.org/dev/examples/notebooks/generated/markov_autoregression.html#Kim,-Nelson,-and-Startz-(1998)-Three-state-Variance-Switching  \n",
    "> Statsmodels Markov Regression https://www.statsmodels.org/devel/examples/notebooks/generated/markov_regression.html   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
